{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from main.utils.get_data import get_dataset\n",
    "\n",
    "from main.utils.analysis_utils import plot_macs_vs_acc,entropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "height = 16\n",
    "width = height*1.6\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams[\"figure.figsize\"] = (width,height)\n",
    "plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['xtick.major.width'] = 1.6\n",
    "plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams['axes.labelcolor'] = \"black\"\n",
    "plt.rcParams['axes.linewidth'] = 1.6\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['font.size'] = 25\n",
    "\n",
    "def get_model_params(directory):\n",
    "    model_param_file = open(directory + '/model_params.json')\n",
    "    model_params = json.load(model_param_file)\n",
    "    if 'loss' not in model_params.keys():\n",
    "        model_params['loss'] = 'cross-entropy'\n",
    "    return model_params\n",
    "def get_label(labels,label):\n",
    "    if label in labels:\n",
    "        label = label+'_'+str(2)\n",
    "        for i in range(3,10):\n",
    "            if label in labels:\n",
    "                label = label+'_'+str(i)\n",
    "            else:\n",
    "                break\n",
    "    labels.append(label)\n",
    "    return labels,label\n",
    "\n",
    "def make_data(id_set,ood_set):\n",
    "    y_1,y_2 = np.zeros(len(id_set)),np.ones(len(ood_set))\n",
    "    return(np.concatenate([id_set,ood_set]),np.concatenate([y_1,y_2]))\n",
    "\n",
    "n_bins = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking kth value\n",
    "\n",
    "green = np.array([83, 250, 0])/255\n",
    "red = np.array([255, 40, 0])/255\n",
    "n = 256  # number of values in the colormap\n",
    "color_list = [green + (red - green) * i / (n - 1) for i in range(n)]\n",
    "cmap = plt.cm.colors.ListedColormap(color_list[::-1])\n",
    "\n",
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/'\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "\n",
    "adversarial = np.load(model_directory + '/adversarial_analysis/knn_distances.npy')\n",
    "epsilons = np.load(model_directory + '/adversarial_analysis/epsilons.npy')\n",
    "\n",
    "clean_values = np.load(model_directory+'/knn_ood/train_'+dataset+'_train/test_'+dataset+'_test/all_k_distances.npy')[:,:,-1]\n",
    "\n",
    "n_tests = adversarial.shape[0]\n",
    "n_branches = adversarial.shape[2]\n",
    "\n",
    "fig, axes = plt.subplots(2, int(n_branches/2))\n",
    "\n",
    "for branch,ax in enumerate(axes.flatten()):\n",
    "    clean_branch = clean_values[:,branch]\n",
    "    ax.set_title('Branch: '+ str(branch+1))\n",
    "    ax.hist(clean_branch,bins=n_bins,label='in distribution',alpha=0.4,color=green,density=True)\n",
    "    # n_high = np.percentile(clean_branch,99)\n",
    "    # ax.vlines(np.array([n_high]),ymin=0,ymax=50,colors=['black'])\n",
    "    for ood_test in range(n_tests):\n",
    "        knn_values = adversarial[ood_test,:,:,:]\n",
    "        adversarial_branch = knn_values[:,branch,-1]\n",
    "        ax.hist(adversarial_branch,bins=n_bins,alpha=0.4,density=True,color=cmap(1-(ood_test/n_tests)))\n",
    "\n",
    "plt.tight_layout()\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=axes, location='right')\n",
    "cbar.set_alpha(0.7)\n",
    "cbar.draw_all()\n",
    "cbar.set_ticks([0,0.33,0.66,1])\n",
    "cbar.set_ticklabels([0.3,0.2,0.1,0])\n",
    "\n",
    "cbar.set_label('$\\epsilon$',rotation=0,fontsize=34)\n",
    "\n",
    "# fig.text(0.5, 0.95, ('Embedding separation with perturbation: $\\epsilon$'), ha='center', va='center', rotation='horizontal',fontsize=30)\n",
    "fig.text(0.0, 0.5, 'Counts', ha='center', va='center', rotation='vertical',fontsize=36)\n",
    "fig.text(0.5, 0.0, 'k$^{th}$ embedding separation', ha='center', va='center', rotation='horizontal',fontsize=36)\n",
    "plt.savefig('main/figures/adv_dists.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AUROC(directory,epsilons,n_thresh=100,dataset='CIFAR10'):\n",
    "    clean_values = np.load(directory+'/knn_ood/train_'+dataset+'_train/test_'+dataset+'_test/all_k_distances.npy')[:,:,-1]\n",
    "    adversarial = np.load(directory + '/adversarial_analysis/knn_distances.npy')[:,:,:,-1]\n",
    "    n_tests = adversarial.shape[0]\n",
    "    n_branches = adversarial.shape[2]\n",
    "    areas = np.zeros((len(epsilons),n_branches))\n",
    "    thresholds = np.linspace(0,100,n_thresh)\n",
    "    for test_idx,epsilon in enumerate(epsilons):\n",
    "        perturbed = adversarial[test_idx,:,:]\n",
    "        for branch in range(n_branches):\n",
    "            clean_branch = clean_values[:,branch]\n",
    "            perturbed_branch = perturbed[:,branch]\n",
    "            TPR = np.zeros(n_thresh)\n",
    "            FPR = np.zeros(n_thresh)\n",
    "            for thresh_idx,thresh in enumerate(thresholds[::-1]):\n",
    "                threshold = np.percentile(clean_branch,thresh)\n",
    "                x,y = make_data(clean_branch,perturbed_branch)\n",
    "                preds = np.array(x>threshold,dtype=int)\n",
    "                conf_mat = confusion_matrix(y,preds)\n",
    "                tp = conf_mat[1,1]\n",
    "                fp = conf_mat[0,1]\n",
    "                tn = conf_mat[0,0]\n",
    "                fn = conf_mat[1,0]\n",
    "\n",
    "                TPR[thresh_idx] = tp/(fn+tp)\n",
    "                FPR[thresh_idx] = fp/(tn+fp)\n",
    "            \n",
    "            areas[test_idx,branch] = np.trapz(TPR,FPR)\n",
    "    return areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch/',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_1/',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_2/',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_3/',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_4/']\n",
    "               \n",
    "epsilons = np.load(directories[0] + '/adversarial_analysis/epsilons.npy')\n",
    "\n",
    "AUROC_curves = list()\n",
    "\n",
    "for directory in directories:\n",
    "    AUROC_curves.append(get_AUROC(directory,epsilons,dataset='CIFAR100'))\n",
    "\n",
    "all_curves = np.stack(AUROC_curves,axis=0)\n",
    "\n",
    "np.save(directories[0]+'/adversarial_analysis/AUROC_adv.npy',all_curves) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch/'\n",
    "all_curves = np.load(model_directory+'/adversarial_analysis/AUROC_adv.npy') \n",
    "\n",
    "n_branches = 4 \n",
    "\n",
    "mean_area = np.mean(all_curves,axis=0)\n",
    "std_area = np.std(all_curves,axis=0)\n",
    "\n",
    "for test_idx,test in enumerate(epsilons):\n",
    "    print('Data:',test)\n",
    "    for branch in range(n_branches):\n",
    "        print('Branch:',branch+1,np.round(mean_area[test_idx,branch],2),'+-',np.round(std_area[test_idx,branch],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_thresh = 100\n",
    "thresholds = np.linspace(0,100,n_thresh)\n",
    "\n",
    "green = np.array([83, 250, 0])/255\n",
    "red = np.array([255, 40, 0])/255\n",
    "n = 256  # number of values in the colormap\n",
    "color_list = [green + (red - green) * i / (n - 1) for i in range(n)]\n",
    "cmap = plt.cm.colors.ListedColormap(color_list[::-1])\n",
    "\n",
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/'\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "\n",
    "adversarial = np.load(model_directory + '/adversarial_analysis/knn_distances.npy')[:,:,:,-1]\n",
    "epsilons = np.load(model_directory + '/adversarial_analysis/epsilons.npy')\n",
    "\n",
    "clean_values = np.load(model_directory+'/knn_ood/train_'+dataset+'_train/test_'+dataset+'_test/all_k_distances.npy')[:,:,-1]\n",
    "\n",
    "\n",
    "n_tests = adversarial.shape[0]\n",
    "n_branches = adversarial.shape[2]\n",
    "\n",
    "fig, axes = plt.subplots(2, int(n_branches/2))\n",
    "plt.tight_layout()\n",
    "areas = np.zeros((n_tests,n_branches))\n",
    "\n",
    "for perturbation in range(n_tests):\n",
    "    perturbed = adversarial[perturbation,:,:]\n",
    "    for branch,ax in enumerate(axes.flatten()):\n",
    "        clean_branch = clean_values[:,branch]\n",
    "        perturbed_branch = perturbed[:,branch]\n",
    "        TPR = np.zeros(n_thresh)\n",
    "        FPR = np.zeros(n_thresh)\n",
    "        decision_boundaries = np.zeros(n_thresh)\n",
    "        for thresh_idx,thresh in enumerate(thresholds[::-1]):\n",
    "            threshold = np.percentile(clean_branch,thresh)\n",
    "            x,y = make_data(clean_branch,perturbed_branch)\n",
    "            preds = np.array(x>threshold,dtype=int)\n",
    "            conf_mat = confusion_matrix(y,preds)\n",
    "            tp = conf_mat[1,1]\n",
    "            fp = conf_mat[0,1]\n",
    "            tn = conf_mat[0,0]\n",
    "            fn = conf_mat[1,0]\n",
    "\n",
    "            TPR[thresh_idx] = tp/(fn+tp)\n",
    "            FPR[thresh_idx] = fp/(tn+fp)\n",
    "        \n",
    "        AUROC = np.trapz(TPR,FPR)\n",
    "        areas[perturbation,branch] = AUROC\n",
    "        ax.set_title('Branch: '+str(branch+1))\n",
    "        ax.plot(FPR,TPR,color=cmap(1-(perturbation/n_tests)),label=('$\\epsilon$'+str(round(epsilons[perturbation],2))+' : '+str(round(AUROC,3))))\n",
    "        # ax.legend(title='AUROC')\n",
    "        # ax.vlines([0.05],0.05,0.95)\n",
    "        # ax.grid(which='major',color='grey', alpha=0.3,linestyle='--', linewidth=1)\n",
    "\n",
    "print(np.round(areas[1:],3))    \n",
    "print(np.round(epsilons[1:],2)) \n",
    "\n",
    "# fig.text(0.5, 0.95, ('Adversarial example detection ROC'), ha='center', va='center', rotation='horizontal',fontsize=30)\n",
    "fig.text(0.0, 0.5, 'TPR', ha='center', va='center', rotation='vertical',fontsize=36)\n",
    "fig.text(0.5, 0.0, 'FPR', ha='center', va='center', rotation='horizontal',fontsize=36)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=axes, location='right')\n",
    "cbar.set_alpha(0.7)\n",
    "cbar.draw_all()\n",
    "cbar.set_ticks([0,0.33,0.66,1])\n",
    "cbar.set_ticklabels([0.3,0.2,0.1,0])\n",
    "\n",
    "cbar.set_label('$\\epsilon$',rotation=0,fontsize=34)\n",
    "plt.savefig('main/figures/adv_roc.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx, array[idx]\n",
    "\n",
    "def log_spacing(value,n_thresh):\n",
    "    diff = 1-value\n",
    "    logs = np.logspace(-2,0,n_thresh)\n",
    "    return logs*diff + value  \n",
    "\n",
    "\n",
    "def run_adversarial_inference(model_directory,train_dataset,epsilon,n_thresh=100,knn_percentile=0.95,detect_ood=True,adaptive=False):\n",
    "    func_outputs = dict()\n",
    "    name = model_directory.split('/')[3] + ' -- ' + model_directory.split('/')[4]\n",
    "\n",
    "    id_outputs = np.load(model_directory+'/outputs.npy')\n",
    "    n_branches = id_outputs.shape[1]\n",
    "    id_labels = np.load(model_directory+'/labels.npy')\n",
    "\n",
    "    powers = np.load(model_directory+'/power_usage.npy')\n",
    "    epsilons = np.load(model_directory+'/../adversarial_analysis/epsilons.npy')\n",
    "    accuracies = np.load(model_directory+'/../adversarial_analysis/accuracies.npy')\n",
    "\n",
    "    index,_ = find_nearest(epsilons,epsilon)\n",
    "\n",
    "    id_knn = np.load(model_directory+'/../knn_ood/train_'+train_dataset+'_train/test_'+train_dataset+'_test/all_k_distances.npy')\n",
    "    adversarial_knn = np.load(model_directory+'/../adversarial_analysis/knn_distances.npy')[index,:,:,:]\n",
    "\n",
    "    branch_predictions = np.argmax(id_outputs,axis=2)\n",
    "\n",
    "    n_id_inputs = branch_predictions.shape[0]\n",
    "    n_ood_inputs = adversarial_knn.shape[0]\n",
    "\n",
    "    ood_labels = np.full(n_ood_inputs,-1)\n",
    "    all_labels = np.concatenate([id_labels,ood_labels])\n",
    "\n",
    "    id_entropies = np.zeros((n_id_inputs,n_branches))\n",
    "    for input_idx in range(n_id_inputs):\n",
    "        for branch_idx in range(n_branches):\n",
    "            id_entropies[input_idx,branch_idx] = entropy(id_outputs[input_idx,branch_idx,:])\n",
    "    \n",
    "    id_exits = np.zeros((n_thresh,n_id_inputs,n_branches))\n",
    "    id_predictions = np.zeros((n_thresh,n_id_inputs))\n",
    "\n",
    "    ood_exits = np.zeros((n_thresh,n_ood_inputs,n_branches))\n",
    "    ood_predictions = np.zeros((n_thresh,n_ood_inputs))\n",
    "\n",
    "    power_usage = np.zeros(n_thresh)\n",
    "\n",
    "    max_entropy = np.log(id_outputs.shape[2])  \n",
    "    thresholds = np.linspace(max_entropy,0,n_thresh)\n",
    "\n",
    "    knn_thresholds = np.zeros((n_branches,n_thresh))\n",
    "    for branch in range(n_branches):\n",
    "        id_branch = id_knn[:,branch,-1]\n",
    "        knn_thresholds[branch,:] = np.percentile(id_branch,knn_percentile*100)\n",
    "        if adaptive == True: \n",
    "            # adaptive_index = int(n_thresh/2)\n",
    "            # percentiles=np.linspace(knn_percentile,1,n_thresh-(adaptive_index+1))\n",
    "            percentiles=log_spacing(knn_percentile,n_thresh)\n",
    "            for p_idx,percentile in enumerate(percentiles):\n",
    "                knn_thresh = np.percentile(id_branch,percentile*100)\n",
    "                # knn_thresholds[branch,p_idx+adaptive_index+1] = knn_thresh\n",
    "                knn_thresholds[branch,p_idx] = knn_thresh\n",
    "    \n",
    "    for thresh_idx,threshold in enumerate(thresholds):\n",
    "        #get ID outputs w/ knn \n",
    "        for inp_idx in range(n_id_inputs):\n",
    "            early_exit = False\n",
    "            for branch_idx,branch_entropy in enumerate(id_entropies[inp_idx,:]):\n",
    "                if id_knn[inp_idx,branch_idx,-1] > knn_thresholds[branch_idx,thresh_idx]:\n",
    "                    id_exits[thresh_idx,inp_idx,branch_idx] = 1\n",
    "                    id_predictions[thresh_idx,inp_idx] = -1\n",
    "                    early_exit=True\n",
    "                    break\n",
    "                if branch_entropy < threshold:\n",
    "                    id_exits[thresh_idx,inp_idx,branch_idx] = 1\n",
    "                    id_predictions[thresh_idx,inp_idx] = branch_predictions[inp_idx,branch_idx] \n",
    "                    early_exit=True\n",
    "                    break\n",
    "            if early_exit == False:\n",
    "                id_exits[thresh_idx,inp_idx,(n_branches-1)] = 1\n",
    "                id_predictions[thresh_idx,inp_idx] = branch_predictions[inp_idx,(n_branches-1)]\n",
    "\n",
    "        #get OOD knn outputs w/ entropy\n",
    "        for inp_idx in range(n_ood_inputs):\n",
    "            if not detect_ood:\n",
    "                ood_exits[:,:,(n_branches-1)] = 1\n",
    "                ood_predictions[:,:] = -2\n",
    "                break\n",
    "            early_exit = False\n",
    "            for branch_idx,knn_distance in enumerate(adversarial_knn[inp_idx,:,-1]):\n",
    "                if knn_distance > knn_thresholds[branch_idx,thresh_idx]:\n",
    "                    ood_exits[thresh_idx,inp_idx,branch_idx] = 1\n",
    "                    ood_predictions[thresh_idx,inp_idx] = -1\n",
    "                    early_exit=True\n",
    "                    break\n",
    "            if early_exit == False:\n",
    "                ood_exits[thresh_idx,inp_idx,(n_branches-1)] = 1\n",
    "                if accuracies[inp_idx,-1,index] == 1:\n",
    "                    ood_predictions[thresh_idx,inp_idx] = -1\n",
    "                else:\n",
    "                    ood_predictions[thresh_idx,inp_idx] = -2\n",
    "\n",
    "        all_exits = np.concatenate([id_exits,ood_exits],axis=1) \n",
    "        power_usage[thresh_idx] = np.dot(np.sum(all_exits[thresh_idx,:],axis=0),powers)\n",
    "        all_predictions = np.concatenate([id_predictions,ood_predictions],axis=1) \n",
    "\n",
    "    ood_accuracy = np.zeros(n_thresh)\n",
    "    id_accuracy = np.zeros(n_thresh)\n",
    "    all_accuracy = np.zeros(n_thresh)\n",
    "    for thresh in range(n_thresh):\n",
    "        id_accuracy[thresh] = np.mean(id_predictions[thresh,:] == id_labels) \n",
    "        ood_accuracy[thresh] = np.mean(ood_predictions[thresh,:] == ood_labels) \n",
    "        all_accuracy[thresh] = np.mean(all_predictions[thresh,:] == all_labels) \n",
    "    \n",
    "    func_outputs['all_predictions'] = all_predictions\n",
    "    func_outputs['power_usage'] = power_usage/len(all_labels)\n",
    "    func_outputs['all_labels'] = all_labels\n",
    "    func_outputs['all_exits'] = all_exits\n",
    "    func_outputs['id_predictions'] = id_predictions\n",
    "    func_outputs['id_labels'] = id_labels\n",
    "    func_outputs['ood_labels'] = ood_labels\n",
    "    func_outputs['id_accuracy'] = id_accuracy\n",
    "    func_outputs['ood_accuracy'] = ood_accuracy\n",
    "    func_outputs['all_accuracy'] = all_accuracy\n",
    "    func_outputs['n_id_samples'] = n_id_inputs\n",
    "    func_outputs['n_ood_samples'] = n_ood_inputs\n",
    "\n",
    "\n",
    "    return func_outputs\n",
    "\n",
    "\n",
    "def plot_ood_power(ax,model_directory,data,epsilon,n_thresh,percentile,detect_ood=True,adaptive=False):\n",
    "    if detect_ood==False:\n",
    "        label = 'None'\n",
    "    else:\n",
    "        label = str(percentile)\n",
    "    func_out = run_adversarial_inference(model_directory,data,epsilon,n_thresh=n_thresh,knn_percentile=percentile,detect_ood=detect_ood,adaptive=adaptive)\n",
    "    ax.plot(func_out['power_usage'],func_out['id_accuracy'],label=label)\n",
    "    standard_error = 1/np.sqrt(func_out['n_id_samples'])\n",
    "    ax.fill_between(func_out['power_usage'],func_out['id_accuracy']-standard_error,func_out['id_accuracy']+standard_error,alpha=0.3)\n",
    "\n",
    "def plot_improvement_power_adv(ax,model_directory,data,epsilon,n_thresh,percentile,detect_ood=True,adaptive=False):\n",
    "    base_value_dict = run_adversarial_inference(model_directory,data,epsilon,n_thresh=n_thresh,knn_percentile=1.0,detect_ood=False,adaptive=False)\n",
    "    base_power,base_acc=base_value_dict['power_usage'],base_value_dict['id_accuracy']\n",
    "\n",
    "    func_out = run_adversarial_inference(model_directory,data,epsilon,n_thresh=n_thresh,knn_percentile=percentile,detect_ood=detect_ood,adaptive=adaptive)\n",
    "    power,acc=func_out['power_usage'],func_out['id_accuracy']\n",
    "    \n",
    "    acc_range = np.linspace(base_acc[0],np.max(acc),500)\n",
    "    max_acc = np.max(base_acc)\n",
    "    interp_power = np.interp(acc_range,base_acc,base_power)\n",
    "\n",
    "    if detect_ood==False:\n",
    "        label = 'None'\n",
    "    else:\n",
    "        label = str(percentile)\n",
    "\n",
    "    interp_power_test = np.interp(acc_range,acc,power)\n",
    "    power_diff = ((interp_power-interp_power_test)/interp_power)*100\n",
    "    cutoff_idx = np.argmin(power_diff>0)\n",
    "    if cutoff_idx == 0:\n",
    "        cutoff_idx=len(interp_power_test-1)\n",
    "\n",
    "    acc_range=(max_acc-acc_range)*100\n",
    "    \n",
    "    ax.plot(acc_range[:cutoff_idx],power_diff[:cutoff_idx],label=label)\n",
    "\n",
    "    sigma=3\n",
    "    interval = sigma*np.sqrt(power_diff/func_out['n_id_samples'])\n",
    "\n",
    "    ax.fill_between(acc_range[:cutoff_idx],power_diff[:cutoff_idx]-interval[:cutoff_idx],power_diff[:cutoff_idx]+interval[:cutoff_idx],alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "n_tests = 4\n",
    "fig, axes = plt.subplots(2, 2,figsize=(width,height))\n",
    "knn_ood_tests = np.linspace(0,0.3,n_tests)\n",
    "\n",
    "for test_idx,epsilon in enumerate(knn_ood_tests):\n",
    "    _,epsilon = find_nearest(epsilons,epsilon)\n",
    "    print('Using closest value for epsilon:',epsilon)\n",
    "    ax = axes.flatten()[test_idx]\n",
    "    ax.set_title('$\\epsilon = $'+ str(round(epsilon,2)))\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=25,percentile=1.0,detect_ood=False)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=25,percentile=1.0,detect_ood=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=25,percentile=0.999,detect_ood=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=25,percentile=0.995,detect_ood=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=25,percentile=0.99,detect_ood=True)\n",
    "    \n",
    "# plt.ylabel('OOD-Aware Accuracy')\n",
    "# plt.xlabel('Power usage (MACs)')\n",
    "h, l = axes.flatten()[-1].get_legend_handles_labels()\n",
    "legend = fig.legend(h,l,title='Adversarial detection percentile',loc='center',bbox_to_anchor=(0.5,1.02),ncol=len(knn_ood_tests))\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig.text(0.5, 0.95, ('OOD detection ROC'), ha='center', va='center', rotation='horizontal',fontsize=30)\n",
    "fig.text(0.0, 0.5, 'Perturbation-Aware Accuracy', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0, 'Power usage (MACs)', ha='center', va='center', rotation='horizontal')\n",
    "plt.savefig('main/figures/adv_powers.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "n_tests = 4\n",
    "fig, axes = plt.subplots(2, 2, figsize= (width,height))\n",
    "knn_ood_tests = np.linspace(0,0.3,n_tests)\n",
    "\n",
    "for test_idx,epsilon in enumerate(knn_ood_tests):\n",
    "    _,epsilon = find_nearest(epsilons,epsilon)\n",
    "    print('Using closest value for epsilon:',epsilon)\n",
    "    ax = axes.flatten()[test_idx]\n",
    "    ax.set_title('$\\epsilon = $'+ str(round(epsilon,2)))\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=1.0,detect_ood=False)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=1.0,detect_ood=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=0.999,detect_ood=True,adaptive=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=0.995,detect_ood=True,adaptive=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=0.99,detect_ood=True,adaptive=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=0.95,detect_ood=True,adaptive=True)\n",
    "    plot_ood_power(ax,model_directory,'CIFAR10',epsilon,n_thresh=250,percentile=0.9,detect_ood=True,adaptive=True)\n",
    "    \n",
    "# plt.ylabel('OOD-Aware Accuracy')\n",
    "# plt.xlabel('Power usage (MACs)')\n",
    "h, l = axes.flatten()[-1].get_legend_handles_labels()\n",
    "legend = fig.legend(h,l,title='Adversarial detection percentile: $\\delta$',loc='center',bbox_to_anchor=(0.5,1.04),ncol=7,fontsize=34)\n",
    "plt.setp(legend.get_title(), multialignment='center',fontsize=34)\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig.text(0.5, 0.95, ('OOD detection ROC'), ha='center', va='center', rotation='horizontal',fontsize=30)\n",
    "fig.text(0.0, 0.5, 'Perturbation-Aware Accuracy', ha='center', va='center', rotation='vertical',fontsize=36)\n",
    "fig.text(0.5, 0, 'Power usage (MACs)', ha='center', va='center', rotation='horizontal',fontsize=36)\n",
    "plt.savefig('main/figures/adv_powers_adaptive.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "n_tests = 6\n",
    "fig, axes = plt.subplots(3, int(n_tests/3),figsize=(25, 25))\n",
    "knn_ood_tests = np.linspace(0,0.3,n_tests)\n",
    "\n",
    "for test_idx,epsilon in enumerate(knn_ood_tests):\n",
    "    _,epsilon = find_nearest(epsilons,epsilon)\n",
    "    print('Using closest value for epsilon:',epsilon)\n",
    "    ax = axes.flatten()[test_idx]\n",
    "    ax.set_title('$\\epsilon = $'+ str(round(epsilon,2))) \n",
    "    plot_improvement_power_adv(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=1.0,detect_ood=True)\n",
    "    plot_improvement_power_adv(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.999,adaptive=True)\n",
    "    plot_improvement_power_adv(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.995,adaptive=True)\n",
    "    plot_improvement_power_adv(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.99,adaptive=True)\n",
    "    plot_improvement_power_adv(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.95,adaptive=True)\n",
    "    plot_improvement_power_adv(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.9,adaptive=True)\n",
    "    # ax.invert_xaxis()\n",
    "    \n",
    "# plt.ylabel('OOD-Aware Accuracy')\n",
    "# plt.xlabel('Power usage (MACs)')\n",
    "h, l = axes.flatten()[-1].get_legend_handles_labels()\n",
    "legend = fig.legend(h,l,title='Adversarial detection percentile',loc='center',bbox_to_anchor=(0.5,1.02),ncol=len(knn_ood_tests))\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig.text(0.5, 0.95, ('OOD detection ROC'), ha='center', va='center', rotation='horizontal',fontsize=30)\n",
    "fig.text(0.5, 0.0,  'Accuracy Drop (%)',ha='center', va='center', rotation='horizontal')\n",
    "fig.text(0.0, 0.5, 'Power Improvement (%)', ha='center', va='center', rotation='vertical')\n",
    "plt.savefig('main/figures/power_improvement_adv.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adv_accuracy(ax,model_directory,data,ood_data,n_thresh,percentile,detect_ood=True,adaptive=False):\n",
    "    base_value_dict = run_adversarial_inference(model_directory,data,ood_data,n_thresh=n_thresh,knn_percentile=1.0,detect_ood=False,adaptive=False)\n",
    "    base_acc=base_value_dict['id_accuracy']\n",
    "\n",
    "    func_out = run_adversarial_inference(model_directory,data,ood_data,n_thresh=n_thresh,knn_percentile=percentile,detect_ood=detect_ood,adaptive=adaptive)\n",
    "    id_acc,ood_acc=func_out['id_accuracy'],func_out['ood_accuracy']\n",
    "    \n",
    "    acc_range = np.linspace(min(base_acc),max(base_acc),500)\n",
    "\n",
    "    max_acc = max(base_acc)\n",
    "\n",
    "    label = str(percentile)\n",
    "    if adaptive:\n",
    "        label = label + ' adaptive'\n",
    "\n",
    "    interp_ood_acc_test = np.interp(acc_range,id_acc,ood_acc)*100\n",
    "\n",
    "    acc_range = (acc_range/max_acc)*100\n",
    "    \n",
    "    ax.plot(acc_range,interp_ood_acc_test,label=label)\n",
    "\n",
    "    sigma=3\n",
    "    interval = sigma*np.sqrt(interp_ood_acc_test/func_out['n_id_samples'])\n",
    "\n",
    "    ax.fill_between(acc_range,interp_ood_acc_test-interval,interp_ood_acc_test+interval,alpha=0.3)\n",
    "\n",
    "    targets = np.array([100,99,95,90])\n",
    "    key_indices = list()\n",
    "\n",
    "    for target in targets:\n",
    "        key_indices.append(np.abs(acc_range - target).argmin())\n",
    "\n",
    "    \n",
    "    return np.round(acc_range[key_indices],0),np.round(interp_ood_acc_test[key_indices],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "n_tests = 10\n",
    "fig, axes = plt.subplots(2, 2,figsize=(25, 25))\n",
    "knn_ood_tests = np.linspace(0,0.3,4)\n",
    "\n",
    "for test_idx,epsilon in enumerate(knn_ood_tests):\n",
    "    _,epsilon = find_nearest(epsilons,epsilon)\n",
    "    print('Using closest value for epsilon:',epsilon)\n",
    "    ax = axes.flatten()[test_idx-1]\n",
    "    ax.clear()\n",
    "    ax.set_title('$\\epsilon = $'+ str(round(epsilon,2))) \n",
    "    print(np.round(epsilon,2),0.999,plot_adv_accuracy(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.999,adaptive=True))\n",
    "    print(np.round(epsilon,2),0.995,plot_adv_accuracy(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.995,adaptive=True))\n",
    "    print(np.round(epsilon,2),0.99,plot_adv_accuracy(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.99,adaptive=True))\n",
    "    print(np.round(epsilon,2),0.99,plot_adv_accuracy(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.95,adaptive=True))\n",
    "    print(np.round(epsilon,2),0.99,plot_adv_accuracy(ax,model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=0.9,adaptive=True))\n",
    "    ax.invert_xaxis()\n",
    "    \n",
    "# plt.ylabel('OOD-Aware Accuracy')\n",
    "# plt.xlabel('Power usage (MACs)')\n",
    "h, l = axes.flatten()[-1].get_legend_handles_labels()\n",
    "legend = fig.legend(h,l,title='Adversarial detection percentile',loc='center',bbox_to_anchor=(0.5,1.02),ncol=len(knn_ood_tests))\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig.text(0.5, 0.95, ('OOD detection ROC'), ha='center', va='center', rotation='horizontal',fontsize=30)\n",
    "fig.text(0.5, 0.0,  'ID Accuracy (%)',ha='center', va='center', rotation='horizontal')\n",
    "fig.text(0.0, 0.5, 'OOD accuracy (%)', ha='center', va='center', rotation='vertical')\n",
    "plt.savefig('main/figures/adv_detection_acc.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "epsilon = 0.3\n",
    "n_thresh = 35\n",
    "\n",
    "base = run_adversarial_inference(model_directory,'CIFAR10',epsilon,n_thresh=n_thresh,knn_percentile=1.0,detect_ood=False,adaptive=False)\n",
    "test = run_adversarial_inference(model_directory,'CIFAR10',epsilon,n_thresh=n_thresh,knn_percentile=0.99,detect_ood=True,adaptive=True)\n",
    "base_acc = base['id_accuracy']\n",
    "test_acc = test['id_accuracy']\n",
    "base_powers=base['power_usage']\n",
    "test_powers=test['power_usage']\n",
    "\n",
    "acc_range = np.linspace(min(base_acc),max(base_acc),500)\n",
    "\n",
    "interp_power_base = np.interp(acc_range,base_acc,base_powers)\n",
    "interp_power_test = np.interp(acc_range,base_acc,test_powers)\n",
    "\n",
    "arrowprops = dict(arrowstyle=\"<->\", linewidth=2, color='dimgrey',connectionstyle=\"arc3\")\n",
    "ax.annotate('$\\Delta$Power', xy=(0, 0), xycoords='figure fraction',xytext=(0.225,0.185), textcoords='figure fraction',fontsize=24,color='dimgrey')\n",
    "ax.annotate(\"\",xy=(0.11, 0.17), xycoords='figure fraction',xytext=(0.42, 0.17), textcoords='figure fraction',arrowprops=arrowprops)\n",
    "\n",
    "ax.annotate('$\\Delta$Acc', xy=(0, 0), xycoords='figure fraction',xytext=(0.445, 0.745), textcoords='figure fraction',fontsize=24,color='dimgrey')\n",
    "ax.annotate(\"\",xy=(0.51, 0.87), xycoords='figure fraction',xytext=(0.51, 0.62), textcoords='figure fraction',arrowprops=arrowprops)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.spines[['left', 'bottom']].set_linewidth(1.5)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "\n",
    "plt.plot(interp_power_base,acc_range,label='Conventional',linewidth=4,color ='sandybrown')\n",
    "plt.plot(interp_power_test,acc_range,label='Distribution Aware',linewidth=4,color='lightseagreen')\n",
    "plt.fill_betweenx(acc_range,interp_power_base,interp_power_test,alpha=0.2,color =['greenyellow'])\n",
    "    \n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Power usage')\n",
    "legend = plt.legend(title='Exiting Algorithm')\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('main/figures/power_improvement_diagram.pdf',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_accuracy(model_directory,data,epsilon,n_thresh,percentile,detect_ood=True,adaptive=False,verbose=True):\n",
    "    base_value_dict = run_adversarial_inference(model_directory,data,1.0,n_thresh=n_thresh,knn_percentile=1.0,detect_ood=False,adaptive=False)\n",
    "    base_acc=base_value_dict['id_accuracy']\n",
    "    base_powers=base_value_dict['power_usage']\n",
    "\n",
    "    min_power = base_powers[0]\n",
    "    min_power_acc = base_acc[0]\n",
    "\n",
    "    func_out = run_adversarial_inference(model_directory,data,epsilon,n_thresh=n_thresh,knn_percentile=percentile,detect_ood=detect_ood,adaptive=adaptive)\n",
    "    ood_powers,ood_acc=func_out['power_usage'],func_out['id_accuracy']\n",
    "    \n",
    "    #accuracy increase\n",
    "    equiv_idx = np.argmin(np.abs(ood_powers-min_power))\n",
    "    peak_accuracy_gain = (ood_acc[equiv_idx]-min_power_acc)*100\n",
    "\n",
    "    #power increase      \n",
    "    max_power_idx = np.argmax(base_powers - ood_powers)\n",
    "    peak_power_gain = ((base_powers[max_power_idx] - ood_powers[max_power_idx])/base_powers[max_power_idx])*100\n",
    "\n",
    "    if verbose:\n",
    "        print('peak accuracy increase: ',np.round(peak_accuracy_gain,4))\n",
    "        print('peak power increase: ',np.round(peak_power_gain,4))\n",
    "    \n",
    "    return peak_accuracy_gain,peak_power_gain\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained-models/CIFAR10/resnet_4_branch/w1.0_d18/300-epoch/analysis/'\n",
    "epsilons = np.load(model_directory + '../adversarial_analysis/epsilons.npy')\n",
    "percentiles = [1.0,0.999,0.995,0.99,0.95,0.9]\n",
    "\n",
    "for test_idx,epsilon in enumerate(epsilons[::3]):\n",
    "    print('\\nEpsilon:',np.round(epsilon,3))\n",
    "    for percentile in percentiles:\n",
    "        print('Percentile:',percentile)\n",
    "        get_metrics_accuracy(model_directory,'CIFAR10',epsilon,n_thresh=50,percentile=percentile,detect_ood=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_1/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_2/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_3/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_4/analysis']\n",
    "\n",
    "epsilons = np.load(directories[0] + '/../adversarial_analysis/epsilons.npy')[::3]\n",
    "percentiles = [1.0,0.999,0.995,0.99,0.95,0.9]\n",
    "\n",
    "all_values = np.zeros((len(directories),len(epsilons),len(percentiles),2))\n",
    "\n",
    "for dir_index,directory in enumerate(directories):\n",
    "    print('in directory:',directory)\n",
    "    for epsilon_idx,epsilon in enumerate(epsilons):\n",
    "        print('\\nepsilon:',epsilon)\n",
    "        for p_index,percentile in enumerate(percentiles):\n",
    "            print(percentile)\n",
    "            acc,pow = get_metrics_accuracy(directory,'CIFAR100',epsilon,n_thresh=50,percentile=percentile,detect_ood=True,verbose=False)\n",
    "\n",
    "            all_values[dir_index,epsilon_idx,p_index,0] = acc\n",
    "            all_values[dir_index,epsilon_idx,p_index,1] = pow\n",
    "\n",
    "np.save(directories[0]+'/peak_values_multirun_adv.npy',all_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "\n",
    "all_vals = np.load(directory+'/peak_values_multirun_adv.npy')\n",
    "\n",
    "epsilons = np.load(directories[0] + '/../adversarial_analysis/epsilons.npy')[::3]\n",
    "percentiles = [1.0,0.999,0.995,0.99,0.95,0.9]\n",
    "\n",
    "\n",
    "for epsilon_idx,epsilon in enumerate(epsilons):\n",
    "    print('\\nepsilon:',epsilon)\n",
    "    for p_index,percentile in enumerate(percentiles):\n",
    "        mean_acc = np.mean(all_vals[:,epsilon_idx,p_index,0])\n",
    "        std_acc = np.std(all_vals[:,epsilon_idx,p_index,0])\n",
    "\n",
    "        mean_power = np.mean(all_vals[:,epsilon_idx,p_index,1])\n",
    "        std_power = np.std(all_vals[:,epsilon_idx,p_index,1])\n",
    "        print(percentile,'\\tacc:',np.round(mean_acc,2),'+-',np.round(std_acc,2))\n",
    "        print(percentile,'\\tpower:',np.round(mean_power,2),'+-',np.round(std_power,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_1/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_2/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_3/analysis',\n",
    "               'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch_4/analysis']\n",
    "\n",
    "n_branches=4\n",
    "fig, axes = plt.subplots(2, int(n_branches/2))\n",
    "epsilons = np.load(directories[0] + '/../adversarial_analysis/epsilons.npy')[::3]\n",
    "percentiles = [1.0,0.999,0.995,0.99,0.95,0.9]\n",
    "detection_values = np.zeros((len(directories),len(epsilons),len(percentiles),4))\n",
    "\n",
    "fig, axes = plt.subplots(2, int(n_branches/2))\n",
    "for dir_idx,directory in enumerate(directories):\n",
    "    print('Directory:',directory)\n",
    "    for epsilon_idx,epsilon in enumerate(epsilons):\n",
    "        print('epsilon:',epsilon)\n",
    "        ax = axes.flatten()[epsilon_idx]\n",
    "        ax.set_title(epsilon)\n",
    "        for p_index,percentile in enumerate(percentiles):\n",
    "            accs,detect_accs = plot_adv_accuracy(ax,directory,'CIFAR100',epsilon,n_thresh=50,percentile=percentile,detect_ood=True,adaptive=True)\n",
    "            print(percentile,accs,detect_accs)\n",
    "            detection_values[dir_idx,epsilon_idx,p_index,:] = detect_accs\n",
    "            \n",
    "np.save(directories[0]+'/detection_accuracies_adv.npy',detection_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'trained-models/CIFAR100/resnet_4_branch/w1.0_d18/300-epoch/analysis'\n",
    "\n",
    "detection_accuracies_ood = np.load(directory+'/detection_accuracies_adv.npy')\n",
    "\n",
    "epsilons = np.load(directories[0] + '/../adversarial_analysis/epsilons.npy')[::3]\n",
    "percentiles = [1.0,0.999,0.995,0.99,0.95,0.9]\n",
    "\n",
    "targets = np.array([100,99,95,90])\n",
    "\n",
    "for epsilon_idx,epsilon in enumerate(epsilons):\n",
    "    print('\\n',epsilon)\n",
    "    for t_index, target in enumerate(targets):\n",
    "        print('target',target)\n",
    "        for p_index,percentile in enumerate(percentiles):\n",
    "            acc_mean = np.mean(detection_accuracies_ood[:,epsilon_idx,p_index,t_index])\n",
    "            acc_std =  np.std(detection_accuracies_ood[:,epsilon_idx,p_index,t_index])\n",
    "            print(percentile,'\\tacc:',np.round(acc_mean,2),'+-',np.round(acc_std,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ef857e124b55432e2482b309d69371dfc95ab97871f7fd2c257ba9fb73b045e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
